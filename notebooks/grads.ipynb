{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://github.com/t-vi/pytorch-tvmisc/blob/master/visualize/bad_grad_viz.ipynb\n",
    "# I've added the grad norm at each edge\n",
    "from graphviz import Digraph\n",
    "import mup\n",
    "import torch\n",
    "from torch.autograd import Variable, Function\n",
    "\n",
    "import babylm.models\n",
    "from transformers import CONFIG_MAPPING, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "def iter_graph(root, callback):\n",
    "    queue = [root]\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        fn = queue.pop()\n",
    "        if fn in seen:\n",
    "            continue\n",
    "        seen.add(fn)\n",
    "        for next_fn, _ in fn.next_functions:\n",
    "            if next_fn is not None:\n",
    "                queue.append(next_fn)\n",
    "        callback(fn)\n",
    "\n",
    "def register_hooks(var):\n",
    "    fn_dict = {}\n",
    "    def hook_cb(fn):\n",
    "        def register_grad(grad_input, grad_output):\n",
    "            fn_dict[fn] = grad_input\n",
    "        fn.register_hook(register_grad)\n",
    "    iter_graph(var.grad_fn, hook_cb)\n",
    "\n",
    "    def is_bad_grad(grad_output):\n",
    "        if grad_output is None:\n",
    "            return False\n",
    "        return grad_output.isnan().any() or (grad_output.abs() >= 1e6).any()\n",
    "\n",
    "    def make_dot():\n",
    "        node_attr = dict(style='filled',\n",
    "                        shape='box',\n",
    "                        align='left',\n",
    "                        fontsize='12',\n",
    "                        ranksep='0.1',\n",
    "                        height='0.2')\n",
    "        dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "\n",
    "        def size_to_str(size):\n",
    "            return '('+(', ').join(map(str, size))+')'\n",
    "\n",
    "        def build_graph(fn):\n",
    "            if hasattr(fn, 'variable'):  # if GradAccumulator\n",
    "                u = fn.variable\n",
    "                node_name = 'Variable\\n ' + size_to_str(u.size())\n",
    "                dot.node(str(id(u)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                assert fn in fn_dict, fn\n",
    "                fillcolor = 'white'\n",
    "                if any(is_bad_grad(gi) for gi in fn_dict[fn]):\n",
    "                    fillcolor = 'red'\n",
    "                dot.node(str(id(fn)), str(type(fn).__name__), fillcolor=fillcolor)\n",
    "            for grad_input, (next_fn, _) in zip(fn_dict[fn], fn.next_functions):\n",
    "                if grad_input is not None:\n",
    "                    grad_mag = torch.linalg.norm(grad_input)\n",
    "                else:\n",
    "                    grad_mag = 0\n",
    "                if next_fn is not None:\n",
    "                    next_id = id(getattr(next_fn, 'variable', next_fn))\n",
    "                    dot.edge(str(next_id), str(id(fn)), label=f'{grad_mag:.6f}')\n",
    "        iter_graph(var.grad_fn, build_graph)\n",
    "\n",
    "        return dot\n",
    "\n",
    "    return make_dot\n",
    "\n",
    "\n",
    "\n",
    "path = './outputs'\n",
    "# model = AutoModelForCausalLM.from_pretrained(path)\n",
    "config = CONFIG_MAPPING['holo']()\n",
    "model = AutoModelForCausalLM.from_config(config)\n",
    "base_shapes = model.mup_base_shapes()\n",
    "mup.set_base_shapes(model, base_shapes)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "num_batches = 2\n",
    "seq_len = 1024\n",
    "\n",
    "tokens = torch.randint(1, tokenizer.vocab_size, (num_batches, seq_len))\n",
    "output = model(tokens, labels=tokens)\n",
    "\n",
    "get_dot = register_hooks(output.loss)\n",
    "output.loss.backward()\n",
    "dot = get_dot()\n",
    "#dot.save('tmp.dot') # to get .dot\n",
    "#dot.render('tmp') # to get SVG\n",
    "dot # in Jupyter, you can just render the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
